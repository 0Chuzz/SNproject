#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Section
Introduction
\end_layout

\begin_layout Subsection
Problem statement
\end_layout

\begin_layout Standard
Embedded computing systems are a unfavorable platform to perform computer
 vision tasks, due to the stringent memory and processing power constraints.
 Traditional algorithms must be modified to accommodate to the hardware
 requirements, so the feasible computer vision tasks are limited.
 In this particular project we focused on two tasks that are fundamental
 for the objective of real time object tracking in a video stream.
 These two tasks are component labeling and trajectory prediction.
 
\end_layout

\begin_layout Standard
Component labeling is the process of splitting the pixels that have been
 detected containing some moving object into separate shapes grouping them
 by adjacency.
 The labeling part is improved upon a previous implementation in the paper
 SCOPESXXX, that uses a union-find algorithm.
 The prediction tasks correlates the shapes detected at a certain point
 in time with the past events, so it recognizes previously seen objects.
 The prediction part uses a Kalman filter calculated upon the centroids
 coordinates of the detected moving shapes.
 
\end_layout

\begin_layout Standard
For testing we used a SEED-EYE board, that consists of a PIC32 CPU with
 128 KB of available RAM and 512K of ROM.
 The SEED-EYE board received images through UART serial line, processed
 them and passed back results and benchmark information back to the PC.
 As a source of images we used the Fudan Pedestrian data-set.
 This data-set comes from a camera mounted in front of the entrance of a
 office building in Shangai.
 The motion detection part needed for the tracking task is already done
 and ground truth black and white images are provided along with the video
 images.
 So the SEED-EYE received already processed images where motion detection
 algorithm outlined person shapes.
 
\end_layout

\begin_layout Standard
This project aim has been to lower the service time as much as possible
 in order to increase the possible frame-rate of a video stream for tracking,
 all while respecting the tight memory constraints.
\end_layout

\begin_layout Subsection
Report structure
\end_layout

\begin_layout Standard
The first chapter is this and is a general introduction to the project,
 its goals and the current state of affairs.
 The second chapter delves into the specifics of the connected components
 labeling tasks, how does it work, how does it respect the constraints and
 how it performs on a real platform.
 The third chapter explains how Kalman filter works, how and why it has
 been used, and how it performs.
 The last chapter contains overall considerations of the tracking task on
 the SEED-EYE and proposals to further improve the metrics of the algorithms.
\end_layout

\begin_layout Standard
\begin_inset Newpage pagebreak
\end_inset


\end_layout

\begin_layout Section
Labeling
\end_layout

\begin_layout Subsection
Introduction
\end_layout

\begin_layout Standard
Connected component labeling is the process that splits pixel where motion
 has been detected into groups related to the shape they belong.
 So the input is a 320x240 black and white image where for each pixel we
 get two possible values, white if motion has been detected, or black if
 not.
 As a result of our labeling algorithms we get a set of blobs, each composted
 exclusively of adjacent pixels.
 
\end_layout

\begin_layout Standard
For a black and white image, using 1 bit per pixel, 9600 bytes are needed
 to store one image, while having a 8 bit label for each pixel implies reserving
 a buffer 76800 bytes per single image.
 On embedded system we can suppose to have from 256k to 64k of total available
 memory for the whole tracking task, so the memory requirements are so stringent
 that only few bits per pixel can be afforded.
 In the following pages we show some developed algorithms that allow component
 labeling to be performed using less than 20k of memory.
\end_layout

\begin_layout Subsection
Reference implementation
\end_layout

\begin_layout Standard
The first algorithm that was taken into consideration is from the paper
 
\begin_inset Quotes eld
\end_inset

SCOPES: Smart Cameras Object Position Estimation System
\begin_inset Quotes erd
\end_inset

 .
 The algorithm performs an union find, where a different label is assigned
 to each motion pixel and adjacent pixel are joined in a single set.
 The image is scanned from the top left and each pixel is assigned a label
 according to the pixel on the top and the pixel on the left according to
 the rule outlined in table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:rules-for-union-find"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="6" columns="3">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Top pixel
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Left Pixel
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Action
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
New label
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Assign label L1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
-
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Assign label L2
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Assign label L3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L4
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
L5
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Union(L4, L5); Assign L4
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Rules for union-find connected component labeling
\begin_inset CommandInset label
LatexCommand label
name "tab:rules-for-union-find"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The result of this is a buffer where each pixel is assigned a label, that
 ties it to a specific blob.
 When the last pixel has ben processed, all the pixels are labeled and all
 blobs have been detected.
\end_layout

\begin_layout Standard
The main problem of this algorithm is that has high memory use, mainly caused
 by the high number of temporary labels required, and so the number of connected
 components is limited by the space used.
 In table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:memory-usage-and"

\end_inset

, we can see that to label the blobs of a complex image the memory requirements
 grows above the available space on a typical embedded system.
 Moreover, according to the data structure used to do the union find algorithm,
 the need temporary labels may lower even more the number of detectable
 blobs.
\end_layout

\begin_layout Standard
\begin_inset Float table
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="4">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bits for pixel
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
bytes total
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
% of RAM used for a SEED-EYE (128 KB)
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
max blobs
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
9600
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
7.5%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
19200
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
15%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
4
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
28800
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
22.5%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
8
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
76800
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
60%
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
256
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Memory usage and blob limits for union-find algorithms
\begin_inset CommandInset label
LatexCommand label
name "tab:memory-usage-and"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The fastest union-find algorithms, for 
\begin_inset Formula $N$
\end_inset

 pixels, have a 
\begin_inset Formula $O(N+NlogN)$
\end_inset

 complexity; though the theoretical space required is very high as it uses
 a number of labels equal of the number of pixels.
 Indeed if the programmer attempts to keep temporary labels to a minimum,
 each merge operation will need to modify each pixel belonging to one of
 the merged groups and so will make the merge more cpu intensive, while
 if the programmer attempts to avoid it the number of needed labels grows
 quickly.
 This is not a problem on a computer where 32 bits labels would be a non-issue,
 while on embedded systems is a concern.
 In figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:worst-case-shape"

\end_inset

 we can see an example blob that is hard to parse for a union find algorithms
 that tries to limit the maximum number of blobs to save memory.
 Indeed as it scans the second row it will need a label for each pixel,
 before joining all the labels while scanning the first row.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename worstcaseuf.png

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Worst case shape for union-find algorithms: high number of temporary labels
\begin_inset CommandInset label
LatexCommand label
name "fig:worst-case-shape"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
First improvement: multi-pass algorithm
\end_layout

\begin_layout Standard
The first modification to the union-find algorithm allows to use only two
 black and white buffers.
 This is possible by altering the behavior of the algorithm when a pixel
 that is disconnected from the first connected blob is detected.
 Instead of createing and assigning a new label, the new pixel is ignored
 and it stays unprocessed.
 Eventually the algorithm will find that the single blob currently being
 processed is still connected to previously ignored pixels.
 So when this happens it performs a further scan of the raster in the opposite
 direction, so from bottom to top, right to left.
 The algorithm keeps scanning back and forth the image in loop until no
 more ignored pixels connected to the blobl are left.
 As a result we obtain a buffer containing a single connected shape, that
 can then be processed separately, and that is deleted from the original
 mask image in order to allow the extraction of the successive blob.
 Figure
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:example-of-multipass"

\end_inset

 shows an example where we can see the starting image and the detected connected
 components after the first and the second pass.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename multipass1.png
	scale 25

\end_inset


\begin_inset Graphics
	filename multipass2.png
	scale 25

\end_inset


\begin_inset Graphics
	filename multipass3.png
	scale 25

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Example of multipass algorithm
\begin_inset CommandInset label
LatexCommand label
name "fig:example-of-multipass"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This changes greatly the behaviour of the union find algorithm, that becomes
 a incremental algorithm as the connected components are extracted from
 the original mask one at a time.
 So at the price of increased CPU usage we can separate the connected components
 with a low memory usage.
 The duration of the algorithm for a single blob depends both on the size
 and on its shape, and the number of raster scans can be very high in worst
 case scenario.
 In figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:worst-case-scenario"

\end_inset

 we can see an image where the pixels can be in such a setting that the
 image is scanned a very high number of times, requiring as much passes
 as pixels, so potentially thousands of passes.
 By fine-tuning the scanning rules the downsides can be relatively be limited
 but keeping a reasonable worst case timing constraint is difficult.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename worstcasemp2.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Worst case scenario for multipass algorithm
\begin_inset CommandInset label
LatexCommand label
name "fig:worst-case-scenario"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For example, intermediate steps can be interrupted early when the pixel
 scanned are at more than one row distance from the previously detected
 pixels.
 Another way to limit the number of raster scans could be to increase the
 number of intermediate buffers for pixel labels, so by utilizing an hybrid
 union-find algorithm.
 This implies using a low number of labels, and using multiple passes when
 they are not enough.
 This create a time-memory trade off scenario, but yet does not solve the
 unpredictability of the number of passes.
\end_layout

\begin_layout Standard
Even if this implementation turned off to be infeasible for the implementation
 of labeling on the SEED-EYE, it provided inspiration for further improvements
 and demonstrated that an incremental approach, where blobs are extracted
 from the image one at a time, is the best approach to limit the memory
 usage instead of using a buffer where the number of blobs is limited.
 Still in order to have a working connected component labeling algorithm
 a new approach is required.
\end_layout

\begin_layout Subsection
Second improvement: 
\begin_inset Quotes eld
\end_inset

labyrinth algorithm
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Standard
A better time bound can be obtained indeed by changing approach.
 The main inspiration for this has been the algorithm to explore a labyrinth,
 where by visiting the rightmost corridor at every intersection the whole
 labyrinth can be visited.
 So the essence of the algorithm is that as soon as the first pixel is found,
 the algorithm starts moving in a direction inside the shape trying to visit
 the next rightmost unvisited point.
 Figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:visiting-a-shape"

\end_inset

 show what direction the algorithm takes while exploring a sample blob.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename labirpass.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Visiting a shape keeping the right
\begin_inset CommandInset label
LatexCommand label
name "fig:visiting-a-shape"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In practice we can consider a black and white image as a graph where each
 white pixel is a node and where adjacent pixels are connected with an edge.
 So a blob is a single connected subgraph, and after the first pixel is
 found the algorithm traverse a spanning tree starting from it.
 As each pixel has at most 4 adjacent pixels, the traverse algorithm tests
 for unvisited pixels at most 4 times, then it never visit it again, so
 we have a strong time bound.
 In figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:connected-pixel-spanning"

\end_inset

 we can see an example of a spanning tree that is traversed by the algorithm.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename labirpassspanningtree.png
	scale 50

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Connected pixels as graph with spanning tree
\begin_inset CommandInset label
LatexCommand label
name "fig:connected-pixel-spanning"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
This algorithm requires 2 black and white buffers, and two bits per pixel
 in a temporary buffer on the stack.
 First it raster scans the image to find the first pixel.
 When a new pixel is found, the output buffer is updated and the scanning
 direction that was used while finding it is stored in the temporary buffer.
 This is required in order to remember which was the adjacent node that
 was parent in the spanning tree.
 Then the algorithms finds the rightmost unvisited pixel.
 For example when the search direction is RIGHT, it checks the pixel on
 directions DOWN, RIGHT, UP in this order.
 When no more unvisited pixel are found, the algorithm moves back to the
 parent pixel, and when the root pixel is reached the algorithm terminates.
 
\end_layout

\begin_layout Standard
Compared to the previous approaches it uses more memory, but each shape
 pixel is visited at most four times.
 Indeed if we get back to the graph representation of the image, we can
 see that for a N blobs if we visit the spanning tree we will move over
 N-1 edges and no loop occurs.
 So the space is bounded by the number of pixel of the image, and time is
 bounded by the number of foreground pixels.
 
\end_layout

\begin_layout Subsection
Correctness analysis
\end_layout

\begin_layout Standard
To test the correctness of the three algorithms we compared the results
 obtained over the images of the pedestrian data-set.
 As all of the three algorithms are fully deterministic, comparing the three
 different implementations should provide identical results.
 Indeed comparing the output for all images in the data-set shows that all
 the results are identical.
 So the only difference between the reference algorithm and the two improvements
 are the memory requirements and the timing.
\end_layout

\begin_layout Subsection
Performance analysis
\end_layout

\begin_layout Standard
Timing measurement were collected from the elaboration for the extraction
 of a single connected component and for total image processing.
 The measurements plotted in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:scatter-plot-of"

\end_inset

 show that the time that the algorithm require to process a single blob
 is linear to the quantity of connected pixel, with a small but not negligible
 constant time part.
 It is interesting to see an outstanding area in the range shortly below
 a thousandth of pixels.
 It consists of eight data points but these outliers deserve a further future
 investigation.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename scatter_labeling.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Scatter plot of timings for parsing a single blob
\begin_inset CommandInset label
LatexCommand label
name "fig:scatter-plot-of"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The total time for processing an image instead is a gamma distribution with
 average of about 30 milliseconds.
 From figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Cumulative-distribution-function"

\end_inset

 we can see the cumulative probability to elaborate a whole image in a certain
 time.
 We can see that 50% of the runs are below 29 milliseconds, 90% below 44
 milliseconds with rare worst cases above 60 milliseconds.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename cdflabeling.png
	scale 60

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Cumulative distribution function of total labeling execution times 
\begin_inset CommandInset label
LatexCommand label
name "fig:Cumulative-distribution-function"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Optimizations
\end_layout

\begin_layout Standard
Since the full shape of the blob is not needed for the subsequent steps,
 instead of saving the blob into a buffer, the synthetic values such as
 bounding box and centroid can be calculated while each pixel is visited.
 This allow to cut off a 9.6 KB buffer used for the blob, and the relative
 initialization and usage time.
 Also when updating the synthetic value some calculation can be shaved off:
 the bounding box can be updated only when moving in a particular direction.
 So when the next visited pixel is on the right only the right side of the
 bounding box will be checked and updated, and so on.
 This allow to reduce four checks performed for each pixel into a single
 one.
 Another thing that can be optimized is the first part of the algorithm,
 the scan for the first pixels.
 In the first implementation each time a new blob is searched the image
 is scanned starting from the top left pixel.
 By saving the last position of the previous scan in two static variables,
 so just using two short int or 4 bytes, the topmost pixel are not scanned
 each time anymore.
\end_layout

\begin_layout Subsection
future work
\end_layout

\begin_layout Standard
In all the algorithms the black and white buffers are considered bit by
 bit, and no attempt is made to exploit CPU word size instead.
 This should lead to performance improvements especially in 32 bits systems.
 Moreover, according to the timing requirements the labeling algorithm can
 be applied to down-scaled images.
\end_layout

\end_body
\end_document
